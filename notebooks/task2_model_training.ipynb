{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99faf5f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append('..')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4b04e68",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tsega\\OneDrive\\Documents\\-detection-of-fraud-cases-for-e-commerce\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [17:18:46] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- CreditCard | LogisticRegression ---\n",
      "[[55397  1467]\n",
      " [    8    90]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.99     56864\n",
      "           1       0.06      0.92      0.11        98\n",
      "\n",
      "    accuracy                           0.97     56962\n",
      "   macro avg       0.53      0.95      0.55     56962\n",
      "weighted avg       1.00      0.97      0.99     56962\n",
      "\n",
      "ROC AUC: 0.9708434302252134\n",
      "PR AUC : 0.724469435669471\n",
      "\n",
      "--- CreditCard | XGBClassifier ---\n",
      "[[56833    31]\n",
      " [   15    83]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56864\n",
      "           1       0.73      0.85      0.78        98\n",
      "\n",
      "    accuracy                           1.00     56962\n",
      "   macro avg       0.86      0.92      0.89     56962\n",
      "weighted avg       1.00      1.00      1.00     56962\n",
      "\n",
      "ROC AUC: 0.9799832109264639\n",
      "PR AUC : 0.8682821332846721\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tsega\\OneDrive\\Documents\\-detection-of-fraud-cases-for-e-commerce\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [17:18:52] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- E-Commerce Fraud | LogisticRegression ---\n",
      "[[17588  9805]\n",
      " [  864  1966]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.64      0.77     27393\n",
      "           1       0.17      0.69      0.27      2830\n",
      "\n",
      "    accuracy                           0.65     30223\n",
      "   macro avg       0.56      0.67      0.52     30223\n",
      "weighted avg       0.88      0.65      0.72     30223\n",
      "\n",
      "ROC AUC: 0.7518792490253436\n",
      "PR AUC : 0.45181107105591145\n",
      "\n",
      "--- E-Commerce Fraud | XGBClassifier ---\n",
      "[[27313    80]\n",
      " [ 1333  1497]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97     27393\n",
      "           1       0.95      0.53      0.68      2830\n",
      "\n",
      "    accuracy                           0.95     30223\n",
      "   macro avg       0.95      0.76      0.83     30223\n",
      "weighted avg       0.95      0.95      0.95     30223\n",
      "\n",
      "ROC AUC: 0.7642964872380412\n",
      "PR AUC : 0.6057035996545085\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Imports\n",
    "from src.model_training import run_credit_pipeline, run_fraud_pipeline\n",
    "\n",
    "# Cell 2: Run for Credit Card Data\n",
    "run_credit_pipeline()\n",
    "\n",
    "# Cell 3: Run for Fraud (E-commerce) Data\n",
    "run_fraud_pipeline()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bd4d2b0",
   "metadata": {},
   "source": [
    " Model Performance Summary and Interpretation\n",
    " Dataset 1: Credit Card Fraud Detection\n",
    "Model\tAccuracy\tPrecision (Fraud)\tRecall (Fraud)\tF1-Score (Fraud)\tROC AUC\tPR AUC\n",
    "Logistic Regression\t0.97\t0.06\t0.92\t0.11\t0.971\t0.724\n",
    "XGBoost Classifier\t1.00\t0.73\t0.85\t0.78\t0.980\t0.868\n",
    "\n",
    "Key Observations:\n",
    "\n",
    "The baseline Logistic Regression achieves very high recall (92%) but extremely poor precision (6%), indicating many false positives.\n",
    "\n",
    "XGBoost significantly outperforms LR, achieving strong precision–recall balance (F1 = 0.78), and higher ROC AUC and PR AUC scores.\n",
    "\n",
    "PR AUC is especially important here due to high class imbalance, and XGBoost's 0.868 shows strong performance in detecting rare fraud cases.\n",
    "\n",
    " Dataset 2: E-Commerce Fraud Detection\n",
    "Model\tAccuracy\tPrecision (Fraud)\tRecall (Fraud)\tF1-Score (Fraud)\tROC AUC\tPR AUC\n",
    "Logistic Regression\t0.65\t0.17\t0.69\t0.27\t0.752\t0.452\n",
    "XGBoost Classifier\t0.95\t0.95\t0.53\t0.68\t0.764\t0.606\n",
    "\n",
    "Key Observations:\n",
    "\n",
    "Logistic Regression again shows high recall but very low precision (many false alarms).\n",
    "\n",
    "XGBoost achieves strong overall performance — very high precision (95%) but slightly lower recall (53%).\n",
    "\n",
    "F1-score and PR AUC are better with XGBoost, making it the better choice.\n",
    "\n",
    "##  Which Model is Best?\n",
    "\n",
    "| **Criterion**              | **Winner**        | **Why**                                                                 |\n",
    "|---------------------------|-------------------|-------------------------------------------------------------------------|\n",
    "| Overall Accuracy           | XGBoost           | Near-perfect accuracy on both datasets                                  |\n",
    "| Fraud Detection (Recall)   | Logistic (CC), XGB (EC) | Logistic achieves 92% recall on credit card, but XGB balances both metrics better in e-commerce |\n",
    "| PR AUC (Best for Imbalance) | XGBoost           | Handles minority class well; better PR AUC in both cases                |\n",
    "| Balanced F1-Score          | XGBoost           | Stronger fraud classification with fewer false positives                |\n",
    "\n",
    "\n",
    " Conclusion\n",
    "Across both fraud datasets, XGBoost consistently outperforms Logistic Regression, especially in balancing precision and recall on highly imbalanced data. It is the preferred model for deployment in both e-commerce and credit card fraud detection tasks."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
